---
title: "Model for categorical choice scenarios (experiments 4 to 6)"
output: 
  html_document: 
    keep_md: yes
date: "2023-04-08"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE, echo=FALSE}
# Load packages
library(tidyverse)
library(gghalves) # for plots
library(patchwork)
library(lme4) # for linear mixed models
library(lmerTest) # p-values for mixed models
library(broom) # for tidy outputs of regressions
library(broom.mixed) # for tidy outputs of linear mixed models
```

```{r, echo=FALSE}
#set general theme for plots
plot_theme <- theme_minimal(base_size = 12) +
  theme(# Bold, bigger title
        plot.title = element_text(face = "bold", size = rel(1.7)),
        # Plain, slightly bigger subtitle that is grey
        plot.subtitle = element_text(face = "plain", size = rel(1.3), color = "grey70"),
        # Bold legend titles
        legend.title = element_text(face = "bold"),
        # Bold axis titles
        axis.title = element_text(face = "bold"))
```

```{r}
# ensure this script returns the same results on each run
set.seed(7643)
```

## Explaining the model

```{r}
# Imagine a situation with 3 choice options
options <- 3
# and a population of n = 999
population <- 999
# and we observe samples of 3
sample <- 3
```


### Define competence and its distribution 

We define competence as the probability of making an accurate choice (among various options). Competence is continuous and ranges from `0` to `1`, where `0` corresponds to pure chance (`1/options`) and `1` corresponds to certainly making the correct choice. 

In our code this measure is called `relative_competence`, while `competence` designates the actual probability of making an accurate choice, ranging from `1/options` to `1`). For example, in a 3-choice-options scenario, an individual with a probability of 1/3 (`competence == 0.333`) to pick the right answer has `relative_competence == 0`. 

We assume that individuals (i) vary in competence and (ii) that competence that it is distributed uniformly in the population. 

```{r}
# 1: Distribution of competence
data <- data.frame(competence = runif(population, min = 1/options, max = 1))

# Create a relative measure of competence that allows to compare across
# different numbers of choice options. 
# This measure varies from 0 = random chance to 1 = definitely right. 
# We use min-max scaling, with min = 1/options and max = 1.
data <- data %>% 
  mutate(relative_competence = (competence - 1/options) / (1 - 1/options) )

# data generating function
ggplot() +
  stat_function(fun = dunif, args = list(min = 0, max = 1)) +
  labs(title = "Uniform distribution of competence from 0 to 1", x = "Competence", y = "P(Competence)") + 
  xlim(0, 1)

# generated population
ggplot(data, aes(x = relative_competence)) +
  geom_histogram() + 
  scale_x_continuous(breaks = seq(from = 0, to = 1, by = 0.1)) + 
  annotate("text", x = 0.9, y = 100, label = paste0("n = ", population), color = "red") +
  labs(title = "(sampled) Population of competence drawn from \n uniform population distribution", 
       y = "Count")
```

### Generate a choice for each individual based on their competence. 

```{r}
# 2: Draw individual answers based on competence levels 
data$answer <- data$competence %>% 
  purrr::map_chr(function(x){ 
    
    answer_options <- c("correct", paste0("false", 1:(options-1)))
    probabilities <- c(x, rep((1-x)/(options-1), options-1))
    
    answer = sample(answer_options, 
                    size = 1, 
                    prob = probabilities
                    )
  }
  )

data <- data %>% 
  mutate(correct = ifelse(str_detect(answer, "correct"), 
                                        TRUE, FALSE))

answers <- ggplot(data, aes(x = answer, fill = correct)) +
  geom_bar() +
  guides(fill = "none") +
  plot_theme

competence_by_answers <- ggplot(data, 
       aes(x = answer, y = relative_competence, fill = correct)) +
geom_half_violin(position = position_nudge(x = -.2),
                     adjust=2, alpha = .8,
                     side = "r") +
  coord_flip() +
  guides(fill = "none") +
  plot_theme

answers + competence_by_answers
```

### Draw samples, assign categories & compare average outcomes

### Randomly draw samples from the population

```{r}
# 3: randomly assign samples in population
data <- data %>% mutate(sample_id = rep(1:(population/sample), sample))
```

### Categorize constellations. 

```{r}
# 4: identify constellations 
data <- data %>% 
  # identify how often a one type of answer occurs in one group
  group_by(sample_id, answer) %>% 
  mutate(n_answer_in_sample = n()) %>% 
  # assign constellations
  group_by(sample_id) %>% 
  mutate(unique_answers = n_distinct(answer),
         # Build a first version of constellation variable
         constellation = case_when(unique_answers == sample ~ "dissensus", 
                                   unique_answers == 1 ~ "consensus",
                                   unique_answers <  sample ~ "majority"
         ),
         # identify minority answers in majority constellations
         minority = ifelse(constellation == "majority", 
                           # report whether occurences of answer within a group
                           # are the minority within that group
                           n_answer_in_sample == min(n_answer_in_sample),
                           # for all other constellations, simply code NA,
                           NA
         ), 
         # identify majority answers in majority constellations
         majority = ifelse(constellation == "majority", 
                           # report whether occurrences of answer within a group
                           # are the majority within that group
                           n_answer_in_sample == max(n_answer_in_sample),
                           # for all other constellations, simply code NA,
                           NA
         ), 
         # modify the constellation variable to distinguish between minority, 
         # intermediate majority, majority and dissensus that is composed of 
         # multiple answers (e.g. 3 options, sample of 6, two per option)
         constellation = case_when(
           is.na(minority) | is.na(majority) ~ constellation, 
           minority == TRUE & majority == TRUE ~ "dissensus",
           minority == TRUE ~ "minority", 
           majority == TRUE ~ "majority", 
           .default = "intermediate majority")
  ) %>% ungroup()
```

### Compute average accuracy/competence by constellation.

```{r}
# 5: calculate accuracy and competence levels per constellation

# identify accurate responses
data <- data %>%
  mutate(accurate = ifelse(answer == "correct", TRUE, FALSE))

# compute the summary statistics by constellation
results <- data %>% 
  group_by(constellation) %>% 
  summarize(average_competence = mean(competence), 
            average_relative_competence = mean(relative_competence),
            average_accuracy = mean(accurate)) %>% 
  # store simulation information
  mutate(population = population, 
         sample = sample, 
         options = options)
```

```{r}
ggplot(results,
       aes(x = constellation, y = average_accuracy, fill = constellation)) +
  geom_half_violin(position = position_nudge(x = -.2),
                   adjust=2, alpha = .8,
                   side = "l") +
  stat_summary(fun = "mean", geom = "point", size = 1, shape = 21) +
  stat_summary(fun = "mean", geom = "line", size = 1, linetype = "dashed") +
  stat_summary(fun.data = "mean_se", geom = "errorbar", width = .2) +
  # Add nice labels
  labs(x = "Convergence", y = "Accuracy") +
  scale_fill_viridis_d(option = "plasma", begin = 0.1) +
  guides(fill = "none") +
  plot_theme + 
  theme(axis.text.x = element_text(angle = 20, hjust = 1)) +
  ylim(c(0, 1))
```

## Functions

### Data generating functions

#### Single population

```{r, echo=FALSE}
simulate_single_population <- function(population, sample, options, 
                                       distribution = "uniform", 
                                       return = "summarized") {
  # Check if population is not divisible by sample without remainder
  if (population %% sample != 0) {
    warning("Population is not divisible by sample without remainder.")
  }
  
  # if necessary, alter population size so that it is divisible by sample without rest
  n_possible_samples <- floor(population/sample)
  
  # Biggest possible population to pick
  possible_population = n_possible_samples * sample
  
  # Issue warning if different population size used
  if (population %% sample != 0) {
    warning(paste0("Chosen population size is ", possible_population))
  }
  # change population value (if divisible without remainder, it'll be the same)
  population = possible_population
  
  # 1: Distribution of competence
  
  if (distribution == "uniform") {
  # randomly draw competence levels
  data <- tibble(id = 1:population,
                 competence = runif(population, min = 1/options, max = 1))
  }
  
  if (distribution == "normal") {
  # randomly draw competence levels
  data <- tibble(id = 1:population,
                 competence = rnorm(population, mean = 0.6, sd = 0.01))
  }
  
  # Create a relative measure of competence that allows to compare across
  # different numbers of choice options. 
  # This measure varies from 0 = random chance to 1 = definitely right. 
  # We use min-max scaling, with min = 1/options and max = 1.
  data <- data %>% 
    mutate(relative_competence = (competence - 1/options) / (1 - 1/options)
           )
  
  # 2: Draw individual answers based on competence levels 
  data$answer <- data$competence %>% 
    purrr::map_chr(function(x){ 
      
      answer_options <- c("correct", paste0("false", 1:(options-1)))
      probabilities <- c(x, rep((1-x)/(options-1), options-1))
      
      answer = sample(answer_options, 
                      size = 1, 
                      prob = probabilities
      )
      return(answer)
      
    }) 
  
  # 3: randomly assign samples in population
  data <- data %>% mutate(sample_id = rep(1:(population/sample), sample))
  
  # 4: identify constellations 
  data <- data %>% 
    # identify how often a one type of answer occurs in one group
    group_by(sample_id, answer) %>% 
  mutate(n_answer_in_sample = n()) %>% 
    # assign constellations
  group_by(sample_id) %>% 
    mutate(unique_answers = n_distinct(answer),
           # Build a first version of constellation variable
           constellation = case_when(unique_answers == sample ~ "dissensus", 
                                     unique_answers == 1 ~ "consensus",
                                     unique_answers <  sample ~ "majority"
           ),
           # identify minority answers in majority constellations
           minority = ifelse(constellation == "majority", 
                             # report whether occurences of answer within a group
                             # are the minority within that group
                             n_answer_in_sample == min(n_answer_in_sample),
                             # for all other constellations, simply code NA,
                             NA
           ), 
           # identify majority answers in majority constellations
           majority = ifelse(constellation == "majority", 
                             # report whether occurrences of answer within a group
                             # are the majority within that group
                             n_answer_in_sample == max(n_answer_in_sample),
                             # for all other constellations, simply code NA,
                             NA
           ), 
           # modify the constellation variable to distinguish between minority, 
           # intermediate majority, majority and dissensus that is composed of 
           # multiple answers (e.g. 3 options, sample of 6, two per option)
           constellation = case_when(
             is.na(minority) | is.na(majority) ~ constellation, 
             minority == TRUE & majority == TRUE ~ "dissensus",
             minority == TRUE ~ "minority", 
             majority == TRUE ~ "majority", 
             .default = "intermediate majority")
           ) %>% ungroup()
  
  # 5: calculate accuracy and competence levels per constellation
  
  # identify accurate responses
  data <- data %>%
    mutate(accurate = ifelse(answer == "correct", TRUE, FALSE))
  
  # compute the summary statistics by constellation
  results <- data %>% 
    group_by(constellation) %>% 
    summarize(average_competence = mean(competence), 
              average_relative_competence = mean(relative_competence),
              average_accuracy = mean(accurate),
              count = n_distinct(sample_id)) %>% 
    # store simulation information
    mutate(population = population, 
           sample = sample, 
           options = options)
  
  if(return == "summarized") {
    return(results)
  } else {
    return(data)
  }
}

```

```{r, echo=FALSE}
# # test output (set return to data above)
# test <- simulate_single_population(population = 600, sample = 6, options = 3, 
#                                    return = "raw data") %>% arrange(sample_id)
# levels(as.factor(test$constellation))
# 
# test %>% filter(constellation == "intermediate majority")
```

#### Various populations

```{r, echo=FALSE}
simulate_various_populations <- function(iterations,...) {
  
  # create data frame with model results for generated samples
  various_populations <- 1:iterations %>% 
    purrr::map_df(function(x){
      # this is essentially a for loop - do the following for each 
      # element in 1:iterations
      
      results <- simulate_single_population(...)
      
      # identify iteration
      results$iteration <- x
      
      # To keep track of progress
      if (x %% 50 == 0) {print(paste("iteration number ", x))}
      
      return(results)
      
    }) %>% 
    # store simulation information
    mutate(total_iterations = iterations)
  
  return(various_populations)
}
```


#### Vary choice options and sample size

This function allows us to investigate how accuracy and competence change with varying the number of choice options and the sample size. 

The simulations that this function executes will take quite some time. Therefore, we do not want to run it every time we render this document. Instead we want to store the output of the power simulation in a `.csv` file, and have an integrated "stop" mechanism to prevent execution when that file already exists. To achieve this, we make `file_name` a mandatory argument. If a file with that name already exists, the function will not be executed.

```{r, echo=FALSE}
# set name
file_name <- "model.csv" # change for new analyses / or delete file to re-use same name

vary_sample_options <- function(vary = "options", file_name, n, ...) {
  
  # only run analysis if a file with that name does not yet exists
  if (!file.exists(paste0("data/", file_name))) {
    
    
    # vary choice options for given sample size
    if (vary == "options") {
      
      # do the `calculate_power()` function for each sample size and store the results
      # in a new variable called `power`
      data <- n %>% purrr::map_df(function(n_option){
                                     # this is essentially a for loop - 
                                     # do the following for each 
                                     # element data$n_subj
                                     
                                     # To keep track of progress
                                     print(paste("tested option number = ", n_option))
                                     
                                     # run power calculation
                                     result <- simulate_various_populations(
                                       options = n_option, ...)
                                     
                                     return(result)
                                     
                                   })
      
      write_csv(data, paste0("data/", file_name))
    }
    
    # vary sample size for given choice option
     if (vary == "sample") {
      
      # do the `calculate_power()` function for each sample size and store the results
      # in a new variable called `power`
      data <- n %>% purrr::map_df(function(n_sample){
                                     # this is essentially a for loop - 
                                     # do the following for each 
                                     # element data$n_subj
                                     
                                     # To keep track of progress
                                     print(paste("tested sample number = ", n_sample))
                                     
                                     # run power calculation
                                     result <- simulate_various_populations(
                                       sample = n_sample, ...)
                                     
                                     return(result)
                                     
                                   })
      
      write_csv(data, paste0("data/", file_name))
    }
  }
}
```

### Plot functions

#### a) Plot various populations

First, we want a function that plots results obtained by the `simulate_various_populations` function. 
```{r, echo=FALSE}
plot_results <- function(data, outcome = "everything") {
  
  d <- data
  
  # make constellation a factor with the right levels
  d$constellation <- fct_relevel(d$constellation, "minority", "dissensus", "intermediate majority", "majority", "consensus")
  
  # extract simulation info
  simulation_info <- d %>% summarize(across(c(population, sample, options, total_iterations), mean)) %>% 
    pivot_longer(everything(), names_to = "parameter", values_to = "value") %>% 
    gridExtra::tableGrob(cols = NULL, rows = NULL)
  
  # make descriptive data
  descriptive <- d %>% 
    group_by(constellation) %>% 
    summarise(count = sum(count)) %>% 
    mutate(rel_freq = round(count / sum(count), digits = 2)) %>% 
    gridExtra::tableGrob(rows = NULL)

  
  # plot for accuracy
  plot_accuracy <- ggplot(d,
                          aes(x = constellation, y = average_accuracy, fill = constellation)) +
    geom_half_violin(position = position_nudge(x = -.2),
                     adjust=2, alpha = .8,
                     side = "l") +
    stat_summary(fun = "mean", geom = "point", size = 1, shape = 21) +
    stat_summary(fun = "mean", geom = "line", size = 1, linetype = "dashed") +
    stat_summary(fun.data = "mean_se", geom = "errorbar", width = .2) +
    # Add nice labels
    labs(x = "Convergence", y = "Accuracy") +
    scale_fill_viridis_d(option = "plasma", begin = 0.1) +
    guides(fill = FALSE) +
    plot_theme + 
    theme(axis.text.x = element_text(angle = 20, hjust = 1)) +
    ylim(c(0, 1))
  
  # plot for competence
  plot_competence <- ggplot(d,
                            aes(x = constellation, y =  average_relative_competence, fill = constellation)) +
    geom_half_violin(position = position_nudge(x = -.2),
                     adjust=2, alpha = .8,
                     side = "l") +
    stat_summary(fun = "mean", geom = "point", size = 1, shape = 21) +
    stat_summary(fun = "mean", geom = "line", size = 1, linetype = "dashed") +
    stat_summary(fun.data = "mean_se", geom = "errorbar", width = .2) +
    # Add nice labels
    labs(x = "Convergence", y = "Competence") +
    scale_fill_viridis_d(option = "plasma", begin = 0.1) +
    guides(fill = FALSE) +
    plot_theme + 
    theme(axis.text.x = element_text(angle = 20, hjust = 1)) +
    ylim(c(0, 1))
  
  # unite tables
  tables <- gridExtra::grid.arrange(descriptive, simulation_info, ncol = 2)
  
  if (outcome == "everything") {
    
    return((plot_accuracy | plot_competence) / tables)
  }
  
  if (outcome == "accuracy") {
    
    return(plot_accuracy)
  }
  
  if (outcome == "competence") {
    
    return(plot_competence)
  }
  
}
```

#### b) Plot varying sample & options

Second, we want a function that plots results obtained by the `vary_sample_options` function. 

```{r, echo=FALSE}
plot_results_vary <- function(data, variable = options) {
  
  d <- data
  
  # Extract variable name as a string
  variable_name <- deparse(substitute(variable))
  
  # retrieve info from choice of variable
  if (variable_name == "options") {
    x_label = "Number of Choice Options"
    title = paste0("Sample: ", d$sample," \n iterations: ", d$total_iterations)
  }
    if (variable_name == "sample") {
    x_label = "Size of informant groups"
    title = paste0("Options: ", d$options," \n iterations: ", d$total_iterations)
  }
  
  # make constellation a factor with the right levels
  d$constellation <- fct_relevel(d$constellation, "minority", "dissensus", "intermediate majority", "majority", "consensus")
  
  # plot for accuracy
  plot_accuracy <- ggplot(d,
                          aes(x = as.factor({{variable}}), y = average_accuracy, fill = constellation)) +
    geom_half_violin(position = position_nudge(x = -.2),
                     adjust=2, alpha = .5,
                     side = "l") +
    stat_summary(fun = "mean", geom = "point", size = 1, shape = 21) +
    stat_summary(fun = "mean", geom = "line", size = 1, linetype = "dashed") +
    stat_summary(fun.data = "mean_se", geom = "errorbar", width = .2) +
    # Add nice labels
    labs(x = x_label, y = "Accuracy") +
    scale_fill_viridis_d(option = "plasma", begin = 0.1, 
                         limits = rev(levels(d$constellation)),
                         direction = -1
    ) +
    plot_theme 
  
  # plot for competence
  plot_competence <- ggplot(d,
                            aes(x = as.factor({{variable}}), y = average_relative_competence, fill = constellation)) +
    geom_half_violin(position = position_nudge(x = -.2),
                     adjust=2, alpha = .5,
                     side = "l") +
    stat_summary(fun = "mean", geom = "point", size = 1, shape = 21) +
    stat_summary(fun = "mean", geom = "line", size = 1, linetype = "dashed") +
    stat_summary(fun.data = "mean_se", geom = "errorbar", width = .2) +
    # Add nice labels
    labs(x = x_label, y = "Relative competence", fill = NULL) + 
    scale_fill_viridis_d(option = "plasma", begin = 0.1, 
                         limits = rev(levels(d$constellation)),
                         direction = -1
    ) +
    plot_theme 
  
  ggpubr::ggarrange(plot_accuracy, plot_competence, common.legend = TRUE) +
    plot_annotation(title = title)
}
```

## Simulation

### Fixed sample and choice options

#### Generate data

```{r}
file_name <- "model_3_sample_3_options.csv" # change for new analyses / or delete file to re-use same name

if (!file.exists(paste0("data/", file_name))) { 
  
  # generate data
  data <- simulate_various_populations(iterations = 1000, population = 999, sample = 3, options = 3)
  
  write_csv(data, paste0("data/", file_name))
}

# read simulated data from .csv files
data_3 <- read_csv(paste0("data/", file_name))

# descriptive
data_3 %>% group_by(constellation) %>% summarise(across(c(average_accuracy, average_competence), mean))
```

#### Plot

```{r}
plot_results(data_3)
plot_accuracy_model <- plot_results(data_3, outcome = "accuracy")
plot_competence_model <- plot_results(data_3, outcome = "competence")
```

#### Analyze

```{r, echo=FALSE}
# possible analysis
regression_data <- data_3 %>%
  mutate(
    # make numeric version of convergence
    convergence = case_when( 
      constellation == "minority" ~ 0, 
      constellation == "dissensus" ~ 1,
      constellation == "majority" ~ 2,
      constellation == "consensus" ~ 3), 
    # scale accuracy to reach from 0 to 100 (instead from 0 to 1)
    average_accuracy = average_accuracy*100,
    # scale competence to reach from 1 to 7 (instead of 0 to 1)
    average_relative_competence = 6*average_relative_competence + 1 
  ) 
  
accuracy_model <- lm(average_accuracy ~ convergence, 
                     data = regression_data)
competence_model <- lm(average_relative_competence ~ convergence, 
                       data = regression_data)

```

### Varying sample and choice options

### Generate data

```{r, message=FALSE}
n <- c(3, 5, 10, 20, 50, 100)

# run simulation and store results in .csv files
vary_sample_options(n = n, vary = "options", iterations = 1000, population = 999, sample = 3, file_name = "model_vary_options_3_sample.csv")
vary_sample_options(n = n, vary = "sample", iterations = 1000, population = 999, options = 3, file_name = "model_vary_sample_3_options.csv")

# read simulated data from .csv files
data_3_options <- read_csv("data/model_vary_options_3_sample.csv")
data_3_sample <- read_csv("data/model_vary_sample_3_options.csv")

```

### Plot

```{r, echo=FALSE}
# plot results
plot_results_vary(data_3_options)
plot_results_vary(data_3_sample, variable = sample)
```

### Analyze

```{r, echo=FALSE}
# possible analysis
regression_data <- data_3_options %>% 
  filter(options %in% c(3, 10)) %>% 
  group_by(iteration, constellation, options) %>% 
  summarise(across(c(average_accuracy, average_relative_competence), mean)) %>% 
  mutate(
    convergence = case_when( 
      constellation == "minority" ~ 0, 
      constellation == "dissensus" ~ 1,
      constellation == "majority" ~ 2,
      constellation == "consensus" ~ 3), 
    options = as.factor(options), 
    # scale accuracy to reach from 0 to 100 (instead from 0 to 1)
    average_accuracy = average_accuracy*100,
    # scale competence to reach from 1 to 7 (instead of 0 to 1)
    average_relative_competence = 6*average_relative_competence + 1
  ) 
  
accuracy <- lm(average_accuracy ~ convergence + options + convergence*options, 
               data = regression_data) 
competence <- lm(average_relative_competence ~ convergence + options, data = regression_data) 

summary(competence)
```

## Compare model vs. participants

```{r, message=FALSE}
# read data from experiments
d <- read_csv("./data/cleaned.csv")

# make a categorical variable from `convergence`
d <- d %>% 
  mutate(convergence_categorical = recode_factor(convergence, 
                                                 `0` = "opposing majority", 
                                                 `1` = "divergence", 
                                                 `2` = "majority", 
                                                 `3` = "consensus",
                                                 .default = NA_character_)
         )
```

### Table

```{r, echo=FALSE}
# Calculate models for participants

# model for accuracy
# random intercept and slope by participants
accuracy_participants <- lmer(accuracy ~ convergence + (1 + convergence | id), 
                                 data = d)
# model for competence
# random intercept and slope by participants
competence_participants <- lmer(competence ~ convergence + 
                           (1 + convergence | id), data = d)
```

```{r, echo=FALSE}
# main result table
modelsummary::modelsummary(list("Accuracy" = accuracy_participants, 
                                "Competence" = competence_participants,
                                "Accuracy" = accuracy_model, 
                                "Competence" = competence_model
                                ),
                           title = 'Participants vs. Model', 
                           stars = TRUE) %>%
  kableExtra::add_header_above(c(" " = 1, "Participants" = 2, "Model" = 2))
```

### Plots

#### Participant data

```{r, echo=FALSE}
# plot for accuracy
plot_accuracy <- ggplot(d,
       aes(x = convergence_categorical, y = accuracy, fill = convergence_categorical)) +
  geom_half_violin(position = position_nudge(x = -.2),
                   adjust=2, alpha = .8,
                   side = "l") +
  stat_summary(fun = "mean", geom = "point", size = 1, shape = 21) +
  stat_summary(fun = "mean", geom = "line", size = 1, linetype = "dashed") +
  stat_summary(fun.data = "mean_se", geom = "errorbar", width = .2) +
  # Add nice labels
  labs(x = "Convergence", y = "Accuracy") +
  scale_fill_viridis_d(option = "plasma", begin = 0.1) +
  guides(fill = FALSE) +
  plot_theme + 
  theme(axis.text.x = element_text(angle = 20, hjust = 1))
```

```{r, echo=FALSE}
# plot for competence
plot_competence <- ggplot(d,
       aes(x = convergence_categorical, y = competence, fill = convergence_categorical)) +
  geom_half_violin(position = position_nudge(x = -.2),
                   adjust=2, alpha = .8,
                   side = "l") +
  stat_summary(fun = "mean", geom = "point", size = 1, shape = 21) +
  stat_summary(fun = "mean", geom = "line", size = 1, linetype = "dashed") +
  stat_summary(fun.data = "mean_se", geom = "errorbar", width = .2) +
  # Add nice labels
  labs(x = "Convergence", y = "Competence") +
  scale_fill_viridis_d(option = "plasma", begin = 0.1) +
  guides(fill = FALSE) +
  plot_theme + 
  theme(axis.text.x = element_text(angle = 20, hjust = 1))
```

#### Combine participant and model

```{r, echo=FALSE}
# accuracy
plot_accuracy <- plot_accuracy + ggtitle("Participants")
plot_accuracy_model <- plot_accuracy_model + ggtitle("Model")

plot_accuracy + plot_accuracy_model
```

```{r, echo=FALSE}
# competence
plot_competence <- plot_competence + ggtitle("Participants")
plot_competence_model <- plot_competence_model + ggtitle("Model")

plot_competence + plot_competence_model
```




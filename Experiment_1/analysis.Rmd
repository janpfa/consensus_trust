---
title: "Analysis experiment 1"
author: "Jan Pf√§nder, Hugo Mercier"
date: "2023-03-09"
output: 
  html_document: 
    keep_md: yes
---

```{r packages, message=FALSE}
library(tidyverse)     # create plots with ggplot, manipulate data, etc.
library(broom.mixed)   # convert regression models into nice tables
library(modelsummary)  # combine multiple regression models into a single table
library(lme4)          # model specification / estimation 
library(lmerTest)      # provides p-values in the output
library(ggpubr)        # stile feature of ggplot
library(gghalves)      # do special plots in ggplot
library(kableExtra)    # for tables
```

```{r, message=FALSE}
d <- read_csv("./data/cleaned.csv")
```

### Some themes and functions

```{r, echo=FALSE}
# round numbers from models
rounded_numbers <- function(x) mutate_if(x, is.numeric, round, 3)

#set general theme for plots
plot_theme <- theme_minimal(base_size = 12) +
  theme(# Bold, bigger title
        plot.title = element_text(face = "bold", size = rel(1.7)),
        # Plain, slightly bigger subtitle that is grey
        plot.subtitle = element_text(face = "plain", size = rel(1.3), color = "grey70"),
        # Bold legend titles
        legend.title = element_text(face = "bold"),
        # Bold axis titles
        axis.title = element_text(face = "bold"))
```

### Hypothesis 1

To assess the effect of convergence on participants' confidence about their guesses, we run a paired t-test.

```{r}
# summary stats
d %>%
  group_by(convergence) %>%
  get_summary_stats(confidence, type = "mean_sd")
```

```{r}
# T-test
t <- t.test(confidence ~ convergence, data = d, paired = TRUE)
t
```

The paired t-test shows a significant difference in confidence ratings between *no convergence* and *convergence*. In convergent conditions, participants were on average more confident by `r abs(t$estimate[[1]])` points (on a scale from 1 to 7).

For a robustness check, we run a mixed model regression analysis of convergence on confidence ratings. The first model (`m1`) includes random intercepts for participants. The second model (`m2`) additionally controls for a fixed effect of our second experimental factor, the number of estimates. Including the factor number as a control will also address RQ1. The third model (`m3`) additionally includes random slopes for participants.

For reference, we also include fixed-only effects regression models.

```{r, echo=FALSE}
# Note that in this table we will include models for both outcome variables

# fixed effects only

# baseline
lm_accuracy <- lm(confidence ~ convergence, data= d)
lm_competence <- lm(competence ~ convergence, data= d)
# control
lm_control_accuracy <- lm(confidence ~ convergence + number, data= d)
lm_control_competence <- lm(competence ~ convergence + number, data= d)

# mixed effects 

# first model with random intercept per participant
m1_accuracy = lmer(confidence ~ convergence + (1|ID), data = d)
m1_competence = lmer(competence ~ convergence + (1|ID), data = d)

# second model which controls for second experimental factor "number"
m2_accuracy = lmer(confidence ~ convergence + number + (1|ID), data = d)
m2_competence = lmer(competence ~ convergence + number + (1|ID), data = d)

# third model which adds a random slope (for convergence effect) per participant
m3_accuracy = lmer(confidence ~ convergence + number + (1 + convergence | ID), data = d)
m3_competence = lmer(confidence ~ convergence + number + (1 + convergence | ID), data = d)
```

```{r, echo=FALSE}
# select models with different outcome variables
panels_accuracy <- list(
  "Baseline" = lm_accuracy,
  "Baseline + control" = lm_control_accuracy, 
  "Random intercept" = m1_accuracy, 
  "Random intercept + control" = m2_accuracy, 
  "Random intercept & slope + control" = m3_accuracy
) 

panels_competence <- list(
  "Baseline" = lm_competence,
  "Baseline + control" = lm_control_competence, 
  "Random intercept" = m1_competence, 
  "Random intercept + control" = m2_competence, 
  "Random intercept & slope + control" = m3_competence
) 

panels <- list(
  "Outcome: Accuracy" = panels_accuracy,
  "Outcome: Competence" = panels_competence
)


modelsummary(panels, 
             shape = "rbind",
             stars = TRUE, 
             statistic = 'p.value',
             title = 'Models estimating effect of convergence on accuracy and competence', 
             gof_omit = "IC|Log|Adj|p\\.value|statistic|se_type") %>%
    add_header_above(c(" " = 1, "Fixed" = 2, "Mixed" = 3))
```

The first linear regression model (`Baseline`) yields the same estimate for the effect of `convergence` as the paired t-test. The second model (`Baseline+Control`) controls for `number`. The effect of convergence remains the same, but there is an additional effect of `number`, statistically significant at the 5%-level: Conditions with a number of estimates increased participants' confidence ratings by 0.18 (on a scale from 1 to 7) on average, holding `convergence` constant.

Next, we calculate the mixed effects models. There will be the "fixed", average effects of `convergence` and `number` that we just found in the standard regression models (also called population-level effects, averages across *all* participants). In addition, there will also be random effects by participants.

We have two extra random parameters:

1.  The estimated standard deviation of the by-participant random intercept, represented by the `SD (Intercept ID)`.
2.  The residual variation (i.e. unexplained variation in `competence` once we account for all effects specified in the model), represented by the `SD (Observations)` term in the Residual group.

The first parameter tells how much `competence` ratings bounce around as we move from participant to participant. We can predict `competence` based on `convergence`, but each participant has their own unique offset (i.e. difference from the fixed intercept). We can think about the participant random effects in terms of percentage of the total residual variance in the model (i.e. the variance that's left given the fixed effects in our model). We can calculate that percentage as $\text{intercept_ID}/ (SD_{\text{intercept_ID}} + SD_{observations})$

The fixed effect of `convergence` remains the same. It, again, remains unchanged when adding `number` as a control variable to the mixed model. The fixed effect of `number` is also the same as in the standard regression model.

In the third mixed model we let both the intercept and the effect of `convergence` vary by participant. This is similar to an *interaction*, where the effect one variable (`convergence`) is allowed to vary by the levels/values of another (`ID`).

We have a new term for participant-specific variation in the `convergence`, which is `SD (convergencenoconv ID)` effect.

The term `Cor (Intercept~convergencenoconv ID)` indicates the correlation between the random terms. A negative correlation means that if the random intercept for a specific participant is higher, the slope tends to be lower and vice versa.

In the third model, too, the fixed effect of `convergence` remains unchanged.

### Hypothesis 2

We will proceed just as with hypothesis 1, but for `competence`.

```{r}
# summary stats
d %>%
  group_by(convergence) %>%
  get_summary_stats(competence, type = "mean_sd")

```

```{r}
# T-test
t <- t.test(competence ~ convergence, data = d, paired = TRUE)
t
```

The paired t-test shows a significant difference in competence ratings between *no convergence* and *convergence*. In convergent conditions, participants were on average more confident by `r abs(t$estimate[[1]])` points (on a scale from 1 to 7).

For a robustness check, we ran the same mixed models as described for confidence.

## RQ2 - Effect of number on accuracy (i.e. 'confidence')

```{r}
# get summary stats by number
d %>% 
  group_by(number) %>% 
  summarise(across(c(confidence, competence),  
                   list(mean = mean, sd = sd)))
```


```{r, echo=FALSE}
# T-tests
# accuracy
t <- t.test(confidence ~ number, data = d, paired = TRUE)
t
# competence
t <- t.test(competence ~ number, data = d, paired = TRUE)
t
```

There is a significant effect of `number` on `accuracy`. However, this effect is small compared to the effect of `convergence`. There is no effect on `competence`.

We find the same results using a mixed model. 

```{r, echo=FALSE}
# as mixed model
accuracy <- lmer(confidence ~ number + (1 | ID), data= d)
competence <- lmer(competence ~ number + (1 | ID), data= d)

modelsummary(list("Accuracy" = accuracy , "Competence" = competence), 
             title = 'Models estimating effect of number', 
             stars = TRUE, 
             statistic = 'p.value')
```


## RQ3 - Interaction between number and convergence on competence

In our test for an interaction, we use effect-coded versions of our variables.

```{r}
# effect-coded ('_eff') interaction with random intercepts
d <- d %>% 
  mutate(convergence_eff = recode(convergence, "noconv" = -0.5, "conv" = +0.5),
         number_eff = recode(number, "small" = -0.5, "large" = +0.5))
```

```{r}
model_interaction = lmer(competence ~ convergence_eff + number_eff + convergence_eff*number_eff +
            (1  | ID), data = d)
tidy(model_interaction)
```

There seems to be only just a significant interaction in a mixed model where we let the intercept vary across participants. It suggests that the positive effect convergence is enhanced when the number of estimates is `large` (compared to `small`).

```{r}
# quick visualization
ggplot(d, aes(x = convergence, y = competence, 
                     shape = number,
                     group = number,
                     color = number)) +
  stat_summary(fun = "mean", geom = "point", size = 3) +
  stat_summary(fun = "mean", geom = "line") +
  stat_summary(fun.data = "mean_se", geom = "errorbar", width = .2) +
  scale_color_manual(values = c("#8c510a", "#80cdc1")) +
  theme_classic()
```

## Visualization

### Main plot

```{r summary-plot}
confidence_plot <- ggplot(data=d, aes(x=confidence, fill=convergence)) + 
  geom_density(adjust=3, alpha=.4)+
  scale_x_continuous(name = "Accuracy (confidence) ratings", breaks = seq(1, 7), 
                     limits=c(1, 7)) +
  scale_y_continuous(name = "Density", limits=c(0, 0.3)) +
    scale_fill_manual(
    name = "Convergence: ",
    labels = c("divergent", "convergent"),
    values = c("#E69F00", "#56B4E9")) +
  guides(fill = guide_legend(title = NULL)) +
  plot_theme 

competence_plot <- ggplot(data=d, aes(x=competence, fill=convergence)) + 
  geom_density(adjust=3, alpha=.4)+
  scale_x_continuous(name = "Competence ratings", breaks = seq(1, 7), 
                     limits=c(1, 7)) +
  scale_y_continuous(name = "Density", limits=c(0, 0.3)) +
    scale_fill_manual(
    name = "Convergence: ",
    labels = c("divergent", "convergent"),
    values = c("#E69F00", "#56B4E9")) +
    guides(fill = guide_legend(title = NULL)) +
  plot_theme 

figure <- ggarrange(confidence_plot, competence_plot, common.legend = T) +
  theme(legend.position="top") 
figure
```

### Other plots

#### Confidence/Accuracy

```{r, include=FALSE}
# make plot data
d_means <- d %>%
  group_by(convergence) %>%
  summarize(mean_confidence=mean(confidence))
```

```{r, echo=FALSE}
# Smoothed density plot
density_plot_smoothed <- ggplot(data=d, aes(x=confidence, fill=convergence)) + 
  geom_density(adjust=2, alpha=.4)+
  scale_x_continuous(name = "Confidence ratings", breaks = seq(1, 7), 
                     limits=c(1, 7)) +
  scale_y_continuous(name = "Density", limits=c(0, 0.3)) +
  geom_vline(data=d_means, aes(xintercept=mean_confidence, 
                                       color=convergence),
             show.legend = FALSE,
             linetype="dashed", size=1.5) +
  geom_text(data = d_means, 
            aes(x = mean_confidence, y = 0.3, 
                label =  paste("mean", round(mean_confidence, digits = 1),
                               sep = " = ")),
            nudge_x = -0.5) +
  scale_fill_manual(
    name = "Convergence: ",
    labels = c("divergent", "convergent"),
    values = c("#E69F00", "#56B4E9")) + 
  scale_color_manual(values = c("#E69F00", "#56B4E9")) +
  guides(fill = guide_legend(title = NULL)) +
  theme_pubr() + 
  # larger axis titles
  theme(axis.title = element_text(size = 20)) +
  theme(legend.text = element_text(size = 15))
density_plot_smoothed
```

```{r, echo=FALSE}
# Bar plot
bar_plot <- ggplot(data=d, aes(x=confidence, fill=convergence)) + 
 geom_bar(alpha=0.4, 
                position="identity")+ 
  scale_x_continuous(name = "Confidence ratings", breaks = seq(1, 7)) +
  scale_y_continuous(name = "Frequency") +
  geom_vline(data=d_means, aes(xintercept=mean_confidence, 
                                       color=convergence),
             show.legend = FALSE,
             linetype="dashed", size=1.5) +
  geom_text(data = d_means, 
            aes(x = mean_confidence, y = 280, 
                label =  paste("mean", round(mean_confidence, digits = 1),
                               sep = " = ")),
            nudge_x = -0.6) +
  scale_fill_manual(
    name = "Convergence: ",
    labels = c("divergent", "convergent"),
    values = c("#E69F00", "#56B4E9")) + 
  scale_color_manual(values = c("#E69F00", "#56B4E9")) +
  guides(fill = guide_legend(title = NULL)) +
  theme_pubr() +
    # larger axis titles
  theme(axis.title = element_text(size = 20)) +
  theme(legend.text = element_text(size = 15))  
bar_plot
```

#### Competence

We start by visualizing the difference in `competence`ratings between *convergence* and *no convergence* conditions.

```{r, include=FALSE}
# make plot data
d_means <- d %>%
  group_by(convergence) %>%
  summarize(mean_competence = mean(competence))
```

```{r, echo=FALSE}
# Smoothed density plot
density_plot_smoothed <- ggplot(data=d, aes(x=competence, fill=convergence)) + 
  geom_density(adjust=3, alpha=.4)+
  scale_x_continuous(name = "Competence ratings", breaks = seq(1, 7), 
                     limits=c(1, 7)) +
  scale_y_continuous(name = "Density", limits=c(0, 0.3)) +
  geom_vline(data=d_means, aes(xintercept=mean_competence, 
                               color=convergence),
             show.legend = FALSE,
             linetype="dashed", size=1.5) +
  geom_text(data = d_means, 
            aes(x = mean_competence, y = 0.3, 
                label =  paste("mean", round(mean_competence, digits = 1),
                               sep = " = ")),
            nudge_x = -0.5) +
  scale_fill_manual(
    name = "Convergence: ",
    labels = c("divergent", "convergent"),
    values = c("#E69F00", "#56B4E9")) + 
  scale_color_manual(values = c("#E69F00", "#56B4E9")) +
  guides(fill = guide_legend(title = NULL)) +
  theme_pubr() + 
  # larger axis titles
  theme(axis.title = element_text(size = 20)) +
  theme(legend.text = element_text(size = 15))
density_plot_smoothed
```
